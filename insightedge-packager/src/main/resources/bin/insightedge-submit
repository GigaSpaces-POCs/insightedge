#!/usr/bin/env bash
set -e

if [ -z "${XAP_HOME}" ]; then
  export XAP_HOME="$(cd $(dirname ${BASH_SOURCE[0]})/../..; pwd)"
fi

# disable randomized hash for string in Python 3.3+
export PYTHONHASHSEED=0

# add datagrid and InsightEdge JARs to job --jars
. ${XAP_HOME}/insightedge/sbin/common-insightedge.sh
INSIGHTEDGE_JARS=$(get_libs ',')

process_args(){
    ARGUMENTS=""
    for i in "$@"
        do
            if [[ $i == "--jars" ]]; then
                ARGUMENTS+="--jars $INSIGHTEDGE_JARS,"
            else ARGUMENTS+="$i "
            fi
        done
    if [[ ! $ARGUMENTS =~ .*--jars.* ]]
    then
       # pyspark-shell arguments order is different
      if [[ $1 == "pyspark-shell-main" ]]; then
        ARGUMENTS="$ARGUMENTS --jars $INSIGHTEDGE_JARS"
      else
        ARGUMENTS=" --jars $INSIGHTEDGE_JARS $ARGUMENTS"
      fi
    fi
    echo $ARGUMENTS
}
ARGS=$(process_args "$@")

exec "${XAP_HOME}"/insightedge/spark/bin/spark-class org.apache.spark.deploy.SparkSubmit $ARGS
